{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsjRPv0u945t2zhcfb0OnD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bogdan-Strat/NLP-with-disaster-tweets/blob/main/NLP_with_disaster_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install num2words\n",
        "! pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P06aQMfsBjMH",
        "outputId": "07615089-2069-4372-c112-32541df68ffc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (0.5.12)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words) (0.6.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234911 sha256=384df0fb3f7e7f39da2de26851a9f976be42648ffa1f014714d6a0efdaeccfc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/3d/88/51a592b9ad17e7899126563698b4e3961983ebe85747228ba6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from num2words import num2words\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import re\n",
        "import emoji\n",
        "import string\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "JCEUN-ta93gb"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z5bxY7uRfAy",
        "outputId": "58eccc8a-6e61-4e14-b440-f0ccc202b9b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoticon_string = r\"\"\"\n",
        "    (?:\n",
        "      [<>]?\n",
        "      [:;=8]                     # eyes\n",
        "      [\\-o\\*\\']?                 # optional nose\n",
        "      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\n",
        "      |\n",
        "      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\n",
        "      [\\-o\\*\\']?                 # optional nose\n",
        "      [:;=8]                     # eyes\n",
        "      [<>]?\n",
        "      |\n",
        "      </?3                       # heart\n",
        "    )\"\"\""
      ],
      "metadata": {
        "id": "s9sGoz2_1dMT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Zm5l6D_vUvcc"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "def lower_text(tweet):\n",
        "    return tweet.lower()\n",
        "\n",
        "def convert_number_to_words(tweet):\n",
        "  tweet_num2words = []\n",
        "  data = tweet.split()\n",
        "\n",
        "  for text in data:\n",
        "    if ',' in text:\n",
        "            parts = text.split(',')\n",
        "            converted_parts = []\n",
        "            for part in parts:\n",
        "                if part.isdigit():\n",
        "                    number_without_comma = int(part)\n",
        "                    converted_parts.append(num2words(number_without_comma))\n",
        "                else:\n",
        "                    converted_parts.append(part)\n",
        "            converted_word = ' '.join(converted_parts)\n",
        "            tweet_num2words.append(converted_word)\n",
        "    elif text.isdigit():\n",
        "      tweet_num2words.append(num2words(text))\n",
        "    else:\n",
        "      tweet_num2words.append(text)\n",
        "  return ' '.join(tweet_num2words)\n",
        "\n",
        "def remove_links(tweet):\n",
        "  return ' '.join([re.sub(r'http\\S+', '', word) for word in tweet.split(\" \")])\n",
        " \n",
        "def remove_emoticons_and_emojis(tweet):\n",
        "  emoticon_re = re.compile(emoticon_string, re.VERBOSE | re.I | re.UNICODE)\n",
        "  tweet = ' '.join([re.sub(emoticon_re, '', word) for word in tweet.split(\" \")])\n",
        "  return emoji.replace_emoji(tweet, replace='')\n",
        " \n",
        "def remove_hashtags_and_mentions(tweet):\n",
        "  tweets_no_hashtags = [re.sub(r'#[a-zA-Z0-9_]+','', word) for word in tweet]\n",
        "  return ' '.join([re.sub(r'@[a-zA-Z0-9_]+','', word) for word in tweets_no_hashtags])\n",
        " \n",
        "def remove_multiple_spaces(tweet):\n",
        "  return  ' '.join([re.sub(r'\\s+', ' ', word).strip() for word in tweet.split(\" \")])\n",
        " \n",
        "'''\n",
        "Aveti grija la cazurile de tipul \"unu,doi\". Daca eliminati punctuatia direct, cele doua cuvinte vor \n",
        "fi concatenate obtinand un singur cuvant \"unudoi\". O alternativa ar fi sa inlocuim \n",
        "mai intai toate caracterele de punctuatie cu spatiu, apoi sa aplicam inca o data metoda de contractie a spatiilor.\n",
        "'''\n",
        " \n",
        "def remove_punctuation(tweet):\n",
        "  tweets_no_punct = [re.sub(r'[^\\w\\s]', ' ', word) for word in tweet.split(\" \")]\n",
        "  return ' '.join([re.sub(r'\\s+', ' ', tweet) for tweet in tweets_no_punct])\n",
        "\n",
        "def preprocess(tweet):\n",
        "  tweet = lower_text(tweet)\n",
        "  tweet = convert_number_to_words(tweet)\n",
        "  tweet = remove_links(tweet)\n",
        "  tweet = remove_emoticons_and_emojis(tweet)\n",
        "  tweet = remove_multiple_spaces(tweet)\n",
        "  tweet = remove_punctuation(tweet)\n",
        " \n",
        "  return tweet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(tweet):\n",
        "  stop_words_nltk = set(stopwords.words('english'))\n",
        "  all_words = [word for word in tweet]\n",
        "  all_words_without_stops = [word for word in all_words if word not in stop_words_nltk]\n",
        "  return all_words_without_stops\n",
        "\n",
        "def lematizer(tweet):\n",
        "  words_lemmatize = []\n",
        "  stemmer = SnowballStemmer(language='english')\n",
        "  for token in tweet:\n",
        "    words_lemmatize.append(stemmer.stem(token))\n",
        "  return words_lemmatize\n",
        "\n",
        "def tokenizer(tweet):\n",
        "  tweet = word_tokenize(tweet)\n",
        "  tweet = remove_stopwords(tweet)\n",
        "  tweet = lematizer(tweet)\n",
        "  return tweet"
      ],
      "metadata": {
        "id": "8fg87_zaztR0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = pd.read_csv(\"train.csv\")  # Assuming you have a CSV file with columns id, body, and label\n",
        "data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "IdfVHa4G4oJb",
        "outputId": "6bf7a26a-c18e-486d-8feb-b50f44f2e49c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id keyword location  \\\n",
              "0         1     NaN      NaN   \n",
              "1         4     NaN      NaN   \n",
              "2         5     NaN      NaN   \n",
              "3         6     NaN      NaN   \n",
              "4         7     NaN      NaN   \n",
              "...     ...     ...      ...   \n",
              "7608  10869     NaN      NaN   \n",
              "7609  10870     NaN      NaN   \n",
              "7610  10871     NaN      NaN   \n",
              "7611  10872     NaN      NaN   \n",
              "7612  10873     NaN      NaN   \n",
              "\n",
              "                                                   text  target  \n",
              "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
              "1                Forest fire near La Ronge Sask. Canada       1  \n",
              "2     All residents asked to 'shelter in place' are ...       1  \n",
              "3     13,000 people receive #wildfires evacuation or...       1  \n",
              "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
              "...                                                 ...     ...  \n",
              "7608  Two giant cranes holding a bridge collapse int...       1  \n",
              "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
              "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
              "7611  Police investigating after an e-bike collided ...       1  \n",
              "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-961a847e-1217-49c0-9cad-6f8606439d2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-961a847e-1217-49c0-9cad-6f8606439d2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-961a847e-1217-49c0-9cad-6f8606439d2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-961a847e-1217-49c0-9cad-6f8606439d2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['text']\n",
        "#X = np.asarray(data[['keyword', 'text']])\n",
        "# Split the data into features (email body) and labels (spam or not spam)\n",
        "\n",
        "y = data['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the email bodies with lowercase preprocessing\n",
        "vectorizer = CountVectorizer(preprocessor=preprocess, tokenizer=tokenizer)\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-L8cVIC4uvi",
        "outputId": "d0b54dd2-4203-4961-ae56-35c395a1974f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = nb_classifier.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = (predictions == y_test).mean()\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_DmrzVlHuPO",
        "outputId": "0952efdc-0caa-4268-de9d-8dd686c26ae8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7918581746552856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Naive Bayes classifier\n",
        "svm_classifier = SVC()\n",
        "svm_classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = svm_classifier.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = (predictions == y_test).mean()\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60Rogo3rAFwm",
        "outputId": "5fef8e2e-c6c3-47b3-e2ce-a5674d8fe66e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7944845699277742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Naive Bayes classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "knn_classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = knn_classifier.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = (predictions == y_test).mean()\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SZYnMjnAGG0",
        "outputId": "995771f8-3315-4681-fb5f-9548d317edc8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.701247537754432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Naive Bayes classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = dt_classifier.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = (predictions == y_test).mean()\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwBrxIRmAGbp",
        "outputId": "afcc1ed0-76c4-4d58-ac01-0a53bc03b71a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7314510833880499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Naive Bayes classifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "rf_classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = rf_classifier.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = (predictions == y_test).mean()\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oEkglzrBrfa",
        "outputId": "8f5bd0de-4a71-4ca6-eaea-52970b93c780"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7813525935653316\n"
          ]
        }
      ]
    }
  ]
}